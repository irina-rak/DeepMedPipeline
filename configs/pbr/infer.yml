# General configuration for inference using a pre-trained model

root_dir: ${oc.env:PWD}
mode: validation  # Mode of operation (e.g., inference, evaluation)

# Paths
paths:
  model_path: /path/to/model  # Path to the pre-trained model
  output_dir: ${root_dir}/results/  # Directory to save inference results

# Data configuration
data:
  name: pbr
  config:
    # dir_test: /path/to/test/data  # Directory containing test data
    batch_size: 1 # Always use 1 for inference due to multiple sizes
    num_workers: 8 # Number of workers for data loading
    cache_rate: 0.0
    margin: 45 # Margin for cropping the input data

# Model configuration
model:
  name: unet            # Name of the model
  config:
    spatial_dims: 3
    in_channels: 1
    out_channels: 4
    channels: [16, 32, 64, 128, 256]
    strides: [2, 2, 2, 2]
    num_res_units: 2
    norm: BATCH
    patch_size: [96, 96, 96]
    save_dir: ${paths.output_dir}  # Directory to save model outputs

# Fabric configuration
fabric:
  accelerator: gpu      # Type of accelerator to use (e.g., gpu, cpu, auto)
  # devices: auto         # Number of devices or "auto" to let Fabric decide, # Multi-GPU is not supported yet due to Fabric implementation
  devices: [0]